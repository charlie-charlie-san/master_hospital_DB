import pandas as pd
import tkinter as tk
from tkinter import filedialog, messagebox
import os
import datetime
import mojimoji
import re
from hashids import Hashids

# ==========================================
# ã€è¨­å®šã€‘ä¿å­˜å…ˆ: ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—/hospital_DB
# ==========================================
BASE_DIR = os.path.expanduser("~/Desktop/hospital_DB")
STORAGE_DIR = os.path.join(BASE_DIR, "2_Storage")
ARCHIVE_DIR = os.path.join(BASE_DIR, "9_Archives")

MASTER_FILE = "master_db.xlsx"
MAPPING_FILE = "id_mapping.xlsx"
FIXED_WHOLESALER_NAME = "ã‚¢ã‚¹ã‚³"

ID_SALT = "Financial_System_Secret_Key_2025" 
ID_LENGTH = 6
ID_ALPHABET = "ABCDEFGHJKMNPQRSTVWXYZ23456789"

CORP_TITLES = ["æ ªå¼ä¼šç¤¾", "æœ‰é™ä¼šç¤¾", "åˆåŒä¼šç¤¾", "ä¸€èˆ¬ç¤¾å›£æ³•äºº", "å…¬ç›Šç¤¾å›£æ³•äºº", "åŒ»ç™‚æ³•äºº", r"\(æ ª\)", r"\(æœ‰\)"]
KANJI_NUM_MAP = str.maketrans("ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹ã€‡", "1234567890")

# ==========================================
# ãƒ­ã‚¸ãƒƒã‚¯
# ==========================================
def normalize_text(text):
    if pd.isna(text): return ""
    text = str(text)
    text = mojimoji.zen_to_han(text, kana=False)
    text = mojimoji.han_to_zen(text, digit=False, ascii=False)
    for title in CORP_TITLES:
        text = re.sub(title, "", text)
    text = text.translate(KANJI_NUM_MAP)
    text = re.sub(r'[\s\-â€ï¼ãƒ¼â€•]+', '', text)
    return text.strip()

def generate_id(index):
    hasher = Hashids(salt=str(ID_SALT), min_length=ID_LENGTH, alphabet=ID_ALPHABET)
    return hasher.encode(index)

def clean_val(val):
    if pd.isna(val) or str(val).strip() == "" or str(val).lower() == "nan": return ""
    return val


def normalize_postal_code(val):
    """
    éƒµä¾¿ç•ªå·ã‚’æ­£è¦åŒ–ã™ã‚‹
    - å…ˆé ­0ãŒæ¶ˆãˆãªã„ã‚ˆã†ã«7æ¡ã‚¼ãƒ­åŸ‹ã‚
    - 3æ¡-4æ¡ã®ãƒã‚¤ãƒ•ãƒ³å½¢å¼ã§å‡ºåŠ›
    """
    if pd.isna(val):
        return ""
    
    # æ•°å€¤å‹ã®å ´åˆã¯æ–‡å­—åˆ—ã«å¤‰æ›
    if isinstance(val, (int, float)):
        val = str(int(val))
    else:
        val = str(val).strip()
    
    if val.lower() in ["nan", "none", "null", "nat", ""]:
        return ""
    
    # å…¨è§’ã‚’åŠè§’ã«
    val = mojimoji.zen_to_han(val)
    # ã€’ãƒãƒ¼ã‚¯å‰Šé™¤
    val = val.replace("ã€’", "").strip()
    # ãƒã‚¤ãƒ•ãƒ³ãƒ»ç©ºç™½ã‚’å‰Šé™¤ã—ã¦æ•°å­—ã®ã¿å–å¾—
    digits_only = re.sub(r"[^\d]", "", val)
    
    # 6æ¡ä»¥ä¸‹ã®å ´åˆã¯7æ¡ã«ã‚¼ãƒ­åŸ‹ã‚ï¼ˆå…ˆé ­ã«0ã‚’è¿½åŠ ï¼‰
    if len(digits_only) <= 6:
        digits_only = digits_only.zfill(7)
    
    # 7æ¡ã®å ´åˆã¯ XXX-XXXX å½¢å¼
    if len(digits_only) == 7:
        return digits_only[:3] + "-" + digits_only[3:]
    
    return val


def parse_date(val):
    """
    æ—¥ä»˜ã‚’è§£æã—ã¦YYYY/MM/DDå½¢å¼ã®æ–‡å­—åˆ—ã§è¿”ã™
    - Excelã‚·ãƒªã‚¢ãƒ«å€¤ï¼ˆ5æ¡ã®æ•°å€¤ï¼‰ã‚‚æ­£ã—ãå¤‰æ›
    - å¤‰æ›ã§ããªã„å ´åˆã¯ç©ºæ–‡å­—ã‚’è¿”ã™
    """
    try:
        if pd.isna(val):
            return ""
        
        # æ—¢ã«datetimeå‹ã®å ´åˆ
        if isinstance(val, (datetime.datetime, datetime.date, pd.Timestamp)):
            return val.strftime("%Y/%m/%d")
        
        # æ•°å€¤å‹ã®å ´åˆï¼ˆExcelã‚·ãƒªã‚¢ãƒ«å€¤ï¼‰
        if isinstance(val, (int, float)):
            # Excelã‚·ãƒªã‚¢ãƒ«å€¤ã‚’æ—¥ä»˜ã«å¤‰æ›
            # å¦¥å½“ãªç¯„å›²ï¼ˆ1900å¹´ã€œ2100å¹´ï¼‰ã‹ãƒã‚§ãƒƒã‚¯
            if 1 <= val <= 73050:  # ç´„1900å¹´ã€œ2100å¹´ã®ç¯„å›²
                parsed = pd.to_datetime(val, unit='D', origin='1899-12-30')
                return parsed.strftime("%Y/%m/%d")
            else:
                return ""
        
        # æ–‡å­—åˆ—ã®å ´åˆ
        val_str = str(val).strip()
        if val_str.lower() in ["nan", "none", "null", "nat", ""]:
            return ""
        
        # æ–‡å­—åˆ—ãŒ5æ¡ã®æ•°å€¤ã®ã¿ã®å ´åˆï¼ˆExcelã‚·ãƒªã‚¢ãƒ«å€¤ãŒæ–‡å­—åˆ—ã¨ã—ã¦èª­ã¾ã‚ŒãŸå ´åˆï¼‰
        if val_str.isdigit() and 4 <= len(val_str) <= 5:
            serial = int(val_str)
            if 1 <= serial <= 73050:
                parsed = pd.to_datetime(serial, unit='D', origin='1899-12-30')
                return parsed.strftime("%Y/%m/%d")
        
        # é€šå¸¸ã®æ—¥ä»˜æ–‡å­—åˆ—ã¨ã—ã¦è§£æ
        parsed = pd.to_datetime(val_str)
        # å¦¥å½“ãªå¹´ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆ1950å¹´ã€œ2100å¹´ï¼‰
        if parsed.year < 1950 or parsed.year > 2100:
            return ""
        return parsed.strftime("%Y/%m/%d")
    except:
        return ""

def find_correct_dataframe(path):
    """
    å…¨ã‚·ãƒ¼ãƒˆã‚’å·¡å›ã—ã€ã€Œç—…é™¢ä½æ‰€ã€ã‹ã¤ã€Œä¾¡æ ¼é©ç”¨é–‹å§‹æ—¥ã€ãŒå«ã¾ã‚Œã‚‹æœ¬å‘½ã‚·ãƒ¼ãƒˆã‚’æ¢ã™
    """
    print(f"ğŸ” å…¨ã‚·ãƒ¼ãƒˆã‚’å³ã—ãã‚¹ã‚­ãƒ£ãƒ³ä¸­...")
    try:
        xls = pd.ExcelFile(path)
        sheet_names = xls.sheet_names
        print(f"   ã‚·ãƒ¼ãƒˆä¸€è¦§: {sheet_names}")

        for sheet in sheet_names:
            # å…ˆé ­20è¡Œã ã‘èª­ã‚€
            df_pre = pd.read_excel(path, sheet_name=sheet, header=None, nrows=20)
            
            for i, row in df_pre.iterrows():
                row_text = " ".join(row.astype(str))
                
                # â˜…ã“ã“ãŒé€²åŒ–ï¼šã€Œä½æ‰€ã€ã ã‘ã§ãªãã€Œä¾¡æ ¼é©ç”¨é–‹å§‹æ—¥ã€ã‚‚ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼
                if "ç—…é™¢ä½æ‰€" in row_text and "ä¾¡æ ¼é©ç”¨" in row_text:
                    print(f"   âœ… æœ¬å‘½ç™ºè¦‹ï¼ ã‚·ãƒ¼ãƒˆå: '{sheet}', ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ: {i+1}è¡Œç›®")
                    return pd.read_excel(path, sheet_name=sheet, header=i)
                
                # ã€Œä½æ‰€ã€ã¯ã‚ã‚‹ã‘ã©ã€Œä¾¡æ ¼é©ç”¨ã€ãŒãªã„å ´åˆï¼ˆæƒœã—ã„ã‚·ãƒ¼ãƒˆï¼‰
                elif "ç—…é™¢ä½æ‰€" in row_text:
                    print(f"   âš ï¸ ã‚¹ã‚­ãƒƒãƒ—: ã‚·ãƒ¼ãƒˆ '{sheet}' ã¯ä½æ‰€ãŒã‚ã‚Šã¾ã™ãŒã€é‡è¦é …ç›®ãŒè¶³ã‚Šã¾ã›ã‚“ã€‚")
        
        print("   âŒ æ¡ä»¶ã‚’æº€ãŸã™å®Œå…¨ãªã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None

    except Exception as e:
        print(f"   âš ï¸ ã‚¹ã‚­ãƒ£ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# ==========================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ==========================================
def rebuild_master():
    # ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ
    for d in [STORAGE_DIR, ARCHIVE_DIR]:
        if not os.path.exists(d): os.makedirs(d)

    # ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ
    root = tk.Tk()
    root.withdraw()
    root.attributes('-topmost', True)
    
    print("ğŸ“‚ å…¥åŠ›ãƒ‡ãƒ¼ã‚¿(Excel)ã‚’é¸æŠã—ã¦ãã ã•ã„...")
    input_path = filedialog.askopenfilename(filetypes=[("Excel Files", "*.xlsx")])
    if not input_path: return

    print(f"ğŸ“– ãƒ•ã‚¡ã‚¤ãƒ«è§£æé–‹å§‹: {os.path.basename(input_path)}")
    
    try:
        df_input = find_correct_dataframe(input_path)

        if df_input is None:
            raise ValueError("ã€Œç—…é™¢ä½æ‰€ã€ã¨ã€Œä¾¡æ ¼é©ç”¨é–‹å§‹æ—¥ã€ã®ä¸¡æ–¹ã‚’æŒã¤ã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        # ã‚«ãƒ©ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°
        COL_MAP = {
            "NAME": "å‹•ç‰©ç—…é™¢æ–½è¨­å",
            "LEGAL": "æ³•äººåï¼ˆæ³•äººã®å ´åˆã®ã¿ï¼‰",
            "REP": "ä»£è¡¨è€…åï¼ˆæ¼¢å­—ï¼‰",
            "ZIP": "ç—…é™¢ éƒµä¾¿ç•ªå·",
            "ADDR": "ç—…é™¢ä½æ‰€",
            "TEL": "ç—…é™¢TELï¼ˆé›»è©±ç•ªå·ï¼‰",
            "EMAIL": "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹",
            "INVOICE": "é©æ ¼è«‹æ±‚æ›¸ç™ºè¡Œäº‹æ¥­è€…ã®ç™»éŒ²ç•ªå·",
            "APP_DATE": "å¥‘ç´„ç· çµæ¸ˆ",
            "PRICE_DATE": "ä¾¡æ ¼é©ç”¨é–‹å§‹æ—¥",
            "CANCEL_DATE": "è§£ç´„æ—¥"
        }

        # å¿…é ˆã‚«ãƒ©ãƒ ãƒã‚§ãƒƒã‚¯
        print(f"   èª­ã¿è¾¼ã‚“ã åˆ—å: {list(df_input.columns)}")
        missing = [v for k, v in COL_MAP.items() if v not in df_input.columns]
        if missing:
            raise ValueError(f"å¿…é ˆã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing}")

        master_rows = []
        mapping_rows = []
        processed_keys = set()
        current_seq = 0

        print("âš™ï¸  å¤‰æ›å‡¦ç†ä¸­...")
        for i, row in df_input.iterrows():
            addr = row.get(COL_MAP["ADDR"])
            tel = row.get(COL_MAP["TEL"])
            if pd.isna(addr) or pd.isna(tel): continue

            k = normalize_text(addr) + normalize_text(tel)
            if k in processed_keys: continue

            current_seq += 1
            uid = generate_id(current_seq)
            p_date = parse_date(row.get(COL_MAP["PRICE_DATE"]))
            # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ•ãƒ©ã‚°: ä¾¡æ ¼é©ç”¨é–‹å§‹æ—¥ãŒæœ‰åŠ¹ãªæ—¥ä»˜ãªã‚‰1ã€ç©ºãªã‚‰0
            is_active = 1 if p_date != "" else 0

            master_rows.append({
                "è‡ªç¤¾UID": uid,
                "å‹•ç‰©ç—…é™¢æ–½è¨­å": clean_val(row.get(COL_MAP["NAME"])),
                "æ³•äººå": clean_val(row.get(COL_MAP["LEGAL"])),
                "ä»£è¡¨è€…å": clean_val(row.get(COL_MAP["REP"])),
                "éƒµä¾¿ç•ªå·": normalize_postal_code(row.get(COL_MAP["ZIP"])),  # ä¿®æ­£: éƒµä¾¿ç•ªå·æ­£è¦åŒ–
                "ä½æ‰€": clean_val(addr),
                "é›»è©±ç•ªå·": clean_val(tel),
                "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹": clean_val(row.get(COL_MAP["EMAIL"])),
                "ã‚¤ãƒ³ãƒœã‚¤ã‚¹ç™»éŒ²ç•ªå·": clean_val(row.get(COL_MAP["INVOICE"])),
                "ç”³è¾¼æ—¥": parse_date(row.get(COL_MAP["APP_DATE"])),
                "ä¾¡æ ¼é©ç”¨é–‹å§‹æ—¥": p_date,
                "ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ•ãƒ©ã‚°": is_active,
                "è§£ç´„æ—¥": parse_date(row.get(COL_MAP["CANCEL_DATE"]))
            })

            mapping_rows.append({
                "è‡ªç¤¾UID": uid,
                "æ–½è¨­å(ç¢ºèªç”¨)": clean_val(row.get(COL_MAP["NAME"])),
                "å¸æ¥­è€…å": FIXED_WHOLESALER_NAME,
                "é©ç”¨é–‹å§‹æ—¥": p_date
            })
            processed_keys.add(k)

        # ä¿å­˜
        if master_rows:
            pd.DataFrame(master_rows).to_excel(os.path.join(STORAGE_DIR, MASTER_FILE), index=False)
            pd.DataFrame(mapping_rows).to_excel(os.path.join(STORAGE_DIR, MAPPING_FILE), index=False)
            
            msg = f"âœ… å®Œäº†ï¼\nä¿å­˜å…ˆ: {STORAGE_DIR}\nä»¶æ•°: {len(master_rows)}ä»¶"
            print(msg)
            messagebox.showinfo("æˆåŠŸ", msg)
            if os.name == 'nt': os.startfile(STORAGE_DIR)
            else: os.system(f"open '{STORAGE_DIR}'")
        else:
            messagebox.showinfo("çµæœ", "ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        messagebox.showerror("ã‚¨ãƒ©ãƒ¼", str(e))

if __name__ == "__main__":
    rebuild_master()